{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "\n",
    "weave.init(\"german_invoices_eval\")\n",
    "\n",
    "weave_ref = \"weave:///capecape/german_invoices_eval/object/qa_german_invoices:vKjWelZ7XSrdFwWxKHaAMgGXKfLrXGkPphMJxP340EQ\"\n",
    "qa_ds = weave.ref(weave_ref).get().rows[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import openai\n",
    "import weave\n",
    "\n",
    "weave.init(\"german_invoices_eval\")\n",
    "\n",
    "# our own Llama 3.2-90B-Vision-Instruct instance\n",
    "client = openai.AsyncOpenAI( \n",
    "  base_url=\"http://195.242.25.198:8032/v1\",\n",
    "  api_key=os.environ.get(\"WANDB_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, base64\n",
    "from typing import Union\n",
    "from PIL import Image\n",
    "\n",
    "def image_to_base64(image_path: Union[str, Image.Image]) -> str:\n",
    "    image = Image.open(image_path) if isinstance(image_path, str) else image_path\n",
    "    byte_arr = io.BytesIO()\n",
    "    image.save(byte_arr, format=\"PNG\")\n",
    "    encoded_string = base64.b64encode(byte_arr.getvalue()).decode(\"utf-8\")\n",
    "    return str(encoded_string)\n",
    "\n",
    "@weave.op\n",
    "async def call_llama(img: Image.Image, questions: list[str]) -> str:\n",
    "    image_base64 = image_to_base64(img)\n",
    "    questions = \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(questions)])\n",
    "    base64_messages = [{\n",
    "            \"role\":\n",
    "            \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"Reply to all the questions with the info from the document: \\n{questions}\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{image_base64}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }]\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"Llama-3.2-90B-Vision-Instruct\",\n",
    "        messages=base64_messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = qa_ds[0]\n",
    "image = sample[\"image\"]\n",
    "questions = [q[\"question\"] for q in sample[\"qa_pairs\"]]\n",
    "answers = [a[\"answer\"] for a in sample[\"qa_pairs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the name of the architect office mentioned in the text?',\n",
       " 'What is the offer number provided in the text?',\n",
       " 'What is the total gross amount quoted in the offer?',\n",
       " 'Who is the offer addressed to?',\n",
       " 'What is the date of the offer?']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/german_invoices_eval/r/call/0192301a-2c65-7e03-94d8-595ed2fe0d66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'**Answer:**\\n\\n1. The architect office mentioned in the text is **Architekturb√ºro Eickh√∂lzer**.\\n2. The offer number provided in the text is **1234**.\\n3. The total gross amount quoted in the offer is **7.735,00 ‚Ç¨**.\\n4. The offer is addressed to **Frau Mia Hobner**.\\n5. The date of the offer is **29.07.2030**.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = await call_llama(image, questions)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Answer:**\n",
      "\n",
      "1. The architect office mentioned in the text is **Architekturb√ºro Eickh√∂lzer**.\n",
      "2. The offer number provided in the text is **1234**.\n",
      "3. The total gross amount quoted in the offer is **7.735,00 ‚Ç¨**.\n",
      "4. The offer is addressed to **Frau Mia Hobner**.\n",
      "5. The date of the offer is **29.07.2030**.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "openai_client = instructor.from_openai(openai.AsyncOpenAI())\n",
    "\n",
    "\n",
    "class Judge(BaseModel):\n",
    "    number_of_correct: int = Field(description=\"The number of questions that the model answered correctly\")\n",
    "    explanation: str = Field(description=\"The explanation for the number of questions that the model answered correctly\")\n",
    "\n",
    "@weave.op\n",
    "def judge_answer(model_output: str, answers: str) -> dict:\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant that determines if an answer is correct and provides an explanation for the correctness or incorrectness of the answer. Be tolerant to spelling mistakes that oculd be related to the OCR extraction of the documents and languages.\"},\n",
    "            {\"role\": \"user\", \n",
    "             \"content\": f\"## Model Output \\n{model_output}\\n\\n## Real Answer\\n{answers}\\nReply with a JSON\",\n",
    "            }\n",
    "        ],\n",
    "        response_model=Judge\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/capecape/german_invoices_eval/r/call/0192301b-f111-7b60-a09c-1fcbe1649503\n",
      "üç© https://wandb.ai/capecape/german_invoices_eval/r/call/0192301b-f116-79c1-9783-8859d16988c0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Judge(number_of_correct=5, explanation=\"The model correctly identified all details from the text: the architect office name, offer number, total gross amount, recipient's name, and the date of the offer. Minor spelling variations due to OCR ('Eickh√∂lzer' vs 'Eickholzer') do not affect the accuracy of the content.\")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await judge_answer(res, answers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a flat version of the dataset, with the questions stacked and answers as a list of strings\n",
    "flat_ds = [{\"image\": sample[\"image\"], \n",
    "            \"questions\": [q[\"question\"] for q in sample[\"qa_pairs\"]],\n",
    "            \"answers\": [q[\"answer\"] for q in sample[\"qa_pairs\"]]} for sample in qa_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = weave.Evaluation(dataset=flat_ds, scorers=[judge_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "await evaluation.evaluate(call_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
